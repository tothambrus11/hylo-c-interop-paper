\subsection{Responsible Research}
\subsubsection{Threats to validity}
This research focused specifically on analyzing interop in statically compiled languages, thus we may have overlooked useful techniques that until now have only been used for managed/interpreted languages.

The presented design in this paper is also not fully validated by implementation, thus additional ABI- or type system-related issues may arise during the follow-up full implementation. To mitigate risks, we aimed at prototyping critical parts of the design and have it reviewed by language experts. Interview with experts were conducted in an open and informal format, and therefore we are not sharing transcripts.

\subsubsection{Use of AI and knowledge management tools}
We found that a significant portion of the knowledge related to cross-language interoperability resides within online documentation, community forums, articles, rather than academic papers. The sheer volume and varying density of relevant information within these resources presented a considerable navigational challenge. To assist in targeted exploration of specific research questions within this landscape, we utilized Gemini 2.5 Pro's Deep Research and documented our findings and sources in Obsidian. In addition, we used Gemini 2.5 Flash for answering questions from the uploaded C23 and C++23 standards, and highlighting relevant sections that we consequently reviewed in detail.

To ensure transparency and enable critical assessment of AI-derived insights, we adopted a systematic recording process. For each significant AI-assisted inquiry, we documented the input prompt, the research methodology generated by the model, and its complete output report, including all cited references. This practice proved crucial when a contradiction in AI-synthesized information was detected. Our records allowed us to trace this discrepancy back to the AI model's reliance on forum discussions where information was partially presented or inaccurate. This incident highlighted the imperative of meticulously validating primary sources before drawing firm conclusionsâ€”a principle of heightened importance when AI is employed to navigate and synthesize information.

Our experience affirms that AI tools can significantly accelerate the initial identification of relevant materials within vast datasets, and they fundamentally augment, rather than replace, critical human oversight and rigorous source vetting. It is crucial to acknowledge that AI usage introduces its own set of risks if not managed with transparency and care. However, purely manual research methodologies are not without their own challenges; the sheer scale of available information and the limited personal experience within the field can amplify the effect of cognitive biases\cite{cognitive-biases} influencing the exploration, potentially resulting in a less exhaustive and incomplete understanding of the topic. We found that the responsible and transparent application of AI, far from being merely a high-risk endeavour, can actually bolster research efforts. When used with caution and transparency, AI can help researchers delve deeper and explore more broadly than might be feasible through manual methods alone, thus reducing some inherent human limitations in processing extensive information.

To manage the collected information, resources, references and notes, we employed Obsidian as our knowledge management environment, adapting the Luhmann's Zettelkasten method\cite{Ahrens2017SmartNotes} to organize our findings. This method involves creating atomic, interlinked notes enriched with tags and metadata, facilitating a granular and networked understanding of the subject matter. The DataView plugin for Obsidian further enhanced our organizational capacity by enabling queries based on these tags and metadata, allowing us, for example, to effectively track the progress of reviewing academic articles and conference talks.

This approach to both AI-assisted exploration and overall information management was intended to ensure the integrity of our findings and maximize their utility to the research community. No further ethical concerns were identified during the research.